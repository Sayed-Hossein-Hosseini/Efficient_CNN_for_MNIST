{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9ITCaxM4DkNcjuPPCOgh/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayed-Hossein-Hosseini/Efficient_CNN_for_MNIST/blob/master/Efficient_CNN_for_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Efficient CNN for MNIST**"
      ],
      "metadata": {
        "id": "F39trtkk52RA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "brG2924Q5794"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "MOqIIkNi7pPZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset**"
      ],
      "metadata": {
        "id": "ATHMe1Y56vua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=1000, shuffle=False)"
      ],
      "metadata": {
        "id": "ruxqaSGi7BFN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model (LightCNN)**"
      ],
      "metadata": {
        "id": "WBkm-F2J6MQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LightCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)  # OutPut: 8x28x28\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1) # OutPut: 16x14x14\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # OutPut: 32x7x7\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)  # OutPut: 32x1x1\n",
        "\n",
        "        self.fc = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.global_pool(x)\n",
        "        x = x.view(-1, 32)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "EKWwPqi-6Mf-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initial Preparation**"
      ],
      "metadata": {
        "id": "MrJjt_fm7oRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, optimizer, and error function\n",
        "model = LightCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "OFfxQ-kf7ohu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Training**"
      ],
      "metadata": {
        "id": "sB7I_qyY8CMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1} finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL0xzKXc8CcI",
        "outputId": "355c734d-7e53-4999-a93c-cc719de47eab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished\n",
            "Epoch 2 finished\n",
            "Epoch 3 finished\n",
            "Epoch 4 finished\n",
            "Epoch 5 finished\n",
            "Epoch 6 finished\n",
            "Epoch 7 finished\n",
            "Epoch 8 finished\n",
            "Epoch 9 finished\n",
            "Epoch 10 finished\n",
            "Epoch 11 finished\n",
            "Epoch 12 finished\n",
            "Epoch 13 finished\n",
            "Epoch 14 finished\n",
            "Epoch 15 finished\n",
            "Epoch 16 finished\n",
            "Epoch 17 finished\n",
            "Epoch 18 finished\n",
            "Epoch 19 finished\n",
            "Epoch 20 finished\n",
            "Epoch 21 finished\n",
            "Epoch 22 finished\n",
            "Epoch 23 finished\n",
            "Epoch 24 finished\n",
            "Epoch 25 finished\n",
            "Epoch 26 finished\n",
            "Epoch 27 finished\n",
            "Epoch 28 finished\n",
            "Epoch 29 finished\n",
            "Epoch 30 finished\n",
            "Epoch 31 finished\n",
            "Epoch 32 finished\n",
            "Epoch 33 finished\n",
            "Epoch 34 finished\n",
            "Epoch 35 finished\n",
            "Epoch 36 finished\n",
            "Epoch 37 finished\n",
            "Epoch 38 finished\n",
            "Epoch 39 finished\n",
            "Epoch 40 finished\n",
            "Epoch 41 finished\n",
            "Epoch 42 finished\n",
            "Epoch 43 finished\n",
            "Epoch 44 finished\n",
            "Epoch 45 finished\n",
            "Epoch 46 finished\n",
            "Epoch 47 finished\n",
            "Epoch 48 finished\n",
            "Epoch 49 finished\n",
            "Epoch 50 finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation**"
      ],
      "metadata": {
        "id": "oQFECWfIDooa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Model accuracy on test data: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTbQ4ejjDo4o",
        "outputId": "82745426-3f94-45fd-eff0-c2ac7b8090d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy on test data: 98.61%\n"
          ]
        }
      ]
    }
  ]
}